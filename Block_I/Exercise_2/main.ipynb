{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Solving the Laplace Equation\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we will solve the Laplace equation on a square domain with various boundary conditions. We will explore different numerical methods including sparse matrix techniques and the Jacobi iterative method, and visualize the results.\n",
    "\n",
    "Let's get started by setting up the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The Laplace equation is a second-order partial differential equation widely used in physics and engineering. We will solve it on a square domain with side length L = 1m and Dirichlet boundary conditions.\n",
    "\n",
    "![Dirichlet boundary conditions example](./images/exercise_2.png)\n",
    "\n",
    "We will discretize the domain into a grid and set up the system of equations to be solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Laplace equation\n",
    "The Laplace equation in two dimensions is given by $$ \\frac{\\partial^2 V}{\\partial x^2} + \\frac{\\partial^2 V}{\\partial y^2} = 0 $$\n",
    "This equation describes the potential $ V(x, y) $ in a region where there are no charges. The goal is to solve this equation over \n",
    "a square domain with side length L = 1 meter, given certain boundary conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretizing the Laplace Equation\n",
    "### Finite Difference Method\n",
    "To solve the Laplace equation numerically, we discretize the continuous domain into a grid of points. The second derivative can be approximated using finite differences:\n",
    "\n",
    "$$ \\frac{\\partial^2 V}{\\partial x^2} \\approx \\frac{V_{i+1,j} - 2V_{i,j} + V_{i-1,j}}{\\Delta x^2} $$\n",
    "\n",
    "where $ \\Delta x $ is the grid spacing. For the $y$-direction, we do the same thing.\n",
    "### Constructing the Matrix Equation\n",
    "Using finite differences, we convert the Laplace equation into a system of linear equations: $$ A V = b $$\n",
    "Here, **$A$** is a sparse matrix that encodes the finite difference template, **$V$** is the vector of unknown potentials, and **$b$** contains the boundary conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Implementing the Sparse Matrix method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will solve the Laplace equation using a sparse matrix approach. Sparse matrices are efficient data structures for representing large matrices that contain many zeros, allowing us to save memory and computation time by only storing the non-zero entries.\n",
    "\n",
    "We begin by discretizing the 2D domain into an $ NÃ—N $ grid, where each grid point corresponds to a discrete approximation of the potential function $V(x,y)$. The Laplace equation in two dimensions can be approximated using finite differences, which converts the continuous equation into a set of linear equations.\n",
    "\n",
    "These linear equations can be expressed in matrix form as $AV=b$, where **$A$** is the coefficient matrix, **$V$** is the vector of unknown potentials at each grid point, and **$b$** contains the known boundary conditions. The matrix **$A$** is sparse because each equation typically involves only a few neighboring grid points, leading to many zero entries.\n",
    "\n",
    "To construct the sparse matrix **$A$**, we first create a tridiagonal matrix, referred to as `B_matrix`, which represents the finite difference stencil for the internal grid points (those not on the boundary). We then use Kronecker products with identity matrices to expand this into the full matrix **$A$**, applying the finite difference stencil across the entire grid.\n",
    "\n",
    "Incorporating the boundary conditions involves modifying both the matrix **$A$** and the vector **$b$**. For Dirichlet boundary conditions, where the potential is fixed on the boundaries, the corresponding entries in **$b$** are set to the boundary potential values, and the matrix **$A$** is adjusted accordingly to enforce these conditions.\n",
    "\n",
    "Once the system of linear equations is set up, we solve it using numpy's `linalg.solve` function, which efficiently handles the sparse structure of the matrix. The solution vector **$V$** is then reshaped into an $N \\times N$ grid, representing the potential field across the entire domain.\n",
    "\n",
    "This method is particularly advantageous for large grid sizes because it efficiently manages the computational complexity and memory requirements inherent in solving elliptic partial differential equations like the Laplace equation. Now, let's implement this in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "\n",
    "def solve_sparse_matrix(N):\n",
    "    V_boundary = 100  # Boundary potential in volts\n",
    "    alpha = 1  # Parameter for matrix construction\n",
    "    \n",
    "    # Main diagonal and off-diagonals of the matrix\n",
    "    main_diag = 2*(1 + alpha)*np.ones(N)\n",
    "    off_diag = -1*np.ones(N-1)\n",
    "    \n",
    "    # Construct the matrix B for the internal points\n",
    "    B_matrix = sparse.diags([main_diag, off_diag, off_diag], [0, -1, 1], shape=(N-2, N-2)).toarray()\n",
    "    B_matrix = sparse.block_diag(([1], B_matrix, [1])).toarray()\n",
    "    \n",
    "    # Identity matrices for tensor product\n",
    "    Identity_full = sparse.eye(N).toarray()\n",
    "    Identity_partial = sparse.diags([np.zeros(N), -np.ones(N), -np.ones(N)], [0, -1, 1], shape=(N, N)).toarray()\n",
    "    Identity_adjusted = np.identity(N-2)\n",
    "    Identity_adjusted = sparse.block_diag(([0], Identity_adjusted, [0])).toarray()\n",
    "    \n",
    "    # Construct the full matrix A using Kronecker products\n",
    "    A_matrix = sparse.kron(Identity_full, B_matrix).toarray() + sparse.kron(Identity_partial, Identity_adjusted).toarray()\n",
    "    \n",
    "    # Modify matrix A for boundary conditions\n",
    "    A_matrix = sparse.block_diag((np.identity(N), A_matrix)).toarray()\n",
    "    A_matrix[N:2*N, :N] = -1*Identity_adjusted\n",
    "        \n",
    "    # Vector of boundary conditions\n",
    "    b_vector = np.zeros((N+1)*N)\n",
    "    b_vector[0:N] = V_boundary  # Applying boundary condition on the first row\n",
    "    \n",
    "    # Solve the system A*V = b\n",
    "    solution = np.linalg.solve(A_matrix, b_vector)\n",
    "    solution = solution[:-N].reshape(N, N)\n",
    "    return solution\n",
    "\n",
    "# Define the grid size\n",
    "N = 50\n",
    "\n",
    "# Solve the Laplace equation using the sparse matrix method\n",
    "solution_sparse = solve_sparse_matrix(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results\n",
    "Now that we have computed the solution to the Laplace equation, we need to visualize the potential distribution across the domain to understand how it varies spatially. We will use two types of plots: contour plots and heatmaps.\n",
    "\n",
    "### Contour Plot\n",
    "A contour plot shows lines of constant potential, helping to visualize the gradients and equipotential lines in the solution. It connects points with the same potential value, making it easier to see how the potential changes across the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of potential values\n",
    "vmin, vmax = solution_sparse.min(), solution_sparse.max()\n",
    "\n",
    "# Contour plot\n",
    "plt.figure()\n",
    "plt.contourf(solution_sparse, alpha=1, cmap=plt.cm.Oranges, vmin=vmin, vmax=vmax)\n",
    "C = plt.contour(solution_sparse, colors='black', vmin=vmin, vmax=vmax)\n",
    "plt.clabel(C, inline=1)\n",
    "plt.title('Solution with Sparse Matrix Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap (imshow)\n",
    "A heatmap provides a color-coded representation of the potential values across the grid. It is useful for quickly identifying regions of high and low potential, giving an immediate sense of the potential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap using imshow\n",
    "plt.figure()\n",
    "plt.imshow(solution_sparse, cmap=plt.cm.inferno, origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.title('Solution with Sparse Matrix Method (imshow)')\n",
    "plt.colorbar(label='Potential (V)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these visualizations, the contour plot gives us a clear view of the potential field's topology, while the heatmap offers a quick and intuitive understanding of the potential distribution across the grid. Together, they provide complementary insights into the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Implementing the Jacobi Method\n",
    "In this section, we will solve the Laplace equation using the Jacobi iterative method. The Jacobi method is a straightforward iterative technique for solving linear systems of equations. It updates the potential at each grid point based on the average of its neighboring points until the solution converges.\n",
    "\n",
    "The Jacobi method is particularly useful for solving large systems where direct methods like matrix inversion may be computationally expensive. It is also easy to implement, making it a good introduction to iterative solvers.\n",
    "\n",
    "To implement the Jacobi method, we follow these steps:\n",
    "\n",
    "1. **Initialization**: Start by initializing the grid with random potential values. Apply the boundary conditions directly to the grid, setting fixed potential values where necessary.\n",
    "\n",
    "2. **Iterative update**: For each interior grid point (i.e., points not on the boundary), update its potential by taking the average of its four neighbors (up, down, left, and right). This process is repeated until the maximum change in potential across the grid is smaller than a predefined tolerance, indicating that the solution has converged.\n",
    "\n",
    "3. **Convergence check**: After each iteration, check the maximum difference between the old and new potential values across all grid points. If this difference is less than the specified tolerance, the solution is considered converged.\n",
    "\n",
    "Let's implement this in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_method(N):\n",
    "    V_boundary = 100  # Boundary potential in volts\n",
    "    tolerance = 1e-3  # Convergence tolerance\n",
    "    potential_matrix = np.random.rand(N, N)  # Initialize the grid with random values\n",
    "    \n",
    "    # Apply boundary conditions\n",
    "    potential_matrix[0, :] = V_boundary  # Top boundary\n",
    "    potential_matrix[1:, 0] = 0          # Left boundary\n",
    "    potential_matrix[N-1, 1:] = 0        # Bottom boundary\n",
    "    potential_matrix[N-1, :] = 0         # Bottom boundary (repeated to include all points)\n",
    "    \n",
    "    # Iterative method to solve the system\n",
    "    while True:\n",
    "        max_error = 0\n",
    "        for i in range(1, N-1):\n",
    "            for j in range(1, N-1):\n",
    "                old_value = potential_matrix[i, j]\n",
    "                potential_matrix[i, j] = 0.25 * (potential_matrix[i+1, j] + potential_matrix[i-1, j] +\n",
    "                                                 potential_matrix[i, j+1] + potential_matrix[i, j-1])\n",
    "                max_error = max(max_error, abs(potential_matrix[i, j] - old_value))\n",
    "        if max_error < tolerance:\n",
    "            break\n",
    "    \n",
    "    return potential_matrix\n",
    "\n",
    "# Define the grid size\n",
    "N = 50\n",
    "\n",
    "# Solve the Laplace equation using the Jacobi method\n",
    "solution_jacobi = jacobi_method(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We proceed as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of potential values for Jacobi solution\n",
    "vmin, vmax = solution_jacobi.min(), solution_jacobi.max()\n",
    "\n",
    "# Contour plot for Jacobi solution\n",
    "plt.figure()\n",
    "plt.contourf(solution_jacobi, alpha=1, cmap=plt.cm.Oranges, vmin=vmin, vmax=vmax)\n",
    "C = plt.contour(solution_jacobi, colors='black', vmin=vmin, vmax=vmax)\n",
    "plt.clabel(C, inline=1)\n",
    "plt.title('Solution with Jacobi Method')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap using imshow for Jacobi solution\n",
    "plt.figure()\n",
    "plt.imshow(solution_jacobi, cmap=plt.cm.inferno, origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.title('Solution with Jacobi Method (imshow)')\n",
    "plt.colorbar(label='Potential (V)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Implementing Neumann Boundary Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will modify our approach to solve the Laplace equation with Neumann boundary conditions. Neumann boundary conditions specify the derivative of the potential on the boundary rather than the potential itself. For this problem, we will impose $ \\frac{\\partial V}{\\partial y} = 0 $ on the vertical walls of the domain, meaning that the potential gradient is zero (no flux across the boundary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle Neumann boundary conditions, we adjust the construction of the sparse matrix. Specifically, we modify the finite difference stencil at the boundaries to enforce that the derivative of the potential is zero.\n",
    "\n",
    "Let's implement this in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_sparse_matrix_neumann(N):\n",
    "    V_boundary = 100  # Boundary potential in volts\n",
    "    alpha = 1  # Parameter for matrix construction\n",
    "    \n",
    "    # Main diagonal and off-diagonals of the matrix\n",
    "    main_diag = 2 * (1 + alpha) * np.ones(N)\n",
    "    off_diag = -1 * np.ones(N-1)\n",
    "    \n",
    "    # Construct matrix B with Neumann boundary conditions\n",
    "    B_matrix = sparse.diags([main_diag, off_diag, off_diag], [0, -1, 1], shape=(N, N)).toarray()\n",
    "    B_matrix[0, 0], B_matrix[N-1, N-1] = 1, 1  # Enforcing Neumann BC\n",
    "    \n",
    "    Identity_full = sparse.eye(N).toarray()\n",
    "    Identity_partial = sparse.diags([np.zeros(N), -np.ones(N-1), -np.ones(N-1)], [0, -1, 1], shape=(N, N)).toarray()\n",
    "    Identity_adjusted = np.identity(N-2)\n",
    "    Identity_adjusted = sparse.block_diag(([0], Identity_adjusted, [0])).toarray()\n",
    "    \n",
    "    A_matrix = sparse.kron(Identity_full, B_matrix).toarray() + sparse.kron(Identity_partial, Identity_adjusted).toarray()\n",
    "    A_matrix = sparse.block_diag((np.identity(N), A_matrix)).toarray()\n",
    "    A_matrix[N:2*N, :N] = -1 * Identity_adjusted\n",
    "        \n",
    "    b_vector = np.zeros((N+1) * N)\n",
    "    b_vector[0:N] = V_boundary  # Boundary conditions on top and bottom\n",
    "    \n",
    "    # Solve the system A*V = b\n",
    "    solution = np.linalg.solve(A_matrix, b_vector)\n",
    "    solution = solution[:-N].reshape(N, N)\n",
    "    return solution\n",
    "\n",
    "# Define the grid size\n",
    "N = 50\n",
    "\n",
    "# Solve the Laplace equation with Neumann boundary conditions\n",
    "solution_neumann = solve_sparse_matrix_neumann(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Neumann Boundary Condition Results\n",
    "Let's visualize the solution obtained with Neumann boundary conditions using both a contour plot and a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the range of potential values for Neumann solution\n",
    "vmin, vmax = solution_neumann.min(), solution_neumann.max()\n",
    "\n",
    "# Contour plot for Neumann boundary conditions\n",
    "plt.figure()\n",
    "plt.contourf(solution_neumann, alpha=1, cmap=plt.cm.Oranges, vmin=vmin, vmax=vmax)\n",
    "C = plt.contour(solution_neumann, colors='black', vmin=vmin, vmax=vmax)\n",
    "plt.clabel(C, inline=1)\n",
    "plt.title('Solution with Neumann Boundary Conditions')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap using imshow for Neumann solution\n",
    "plt.figure()\n",
    "plt.imshow(solution_neumann, cmap=plt.cm.inferno, origin='lower', vmin=vmin, vmax=vmax)\n",
    "plt.title('Solution with Neumann Boundary Conditions (imshow)')\n",
    "plt.colorbar(label='Potential (V)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Performance comparison of Numerical Methods\n",
    "In this section, we will compare the performance of the Sparse Matrix method and the Jacobi method for solving the Laplace equation. Understanding the computational efficiency of these methods is crucial, especially when dealing with large-scale problems in scientific computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Background\n",
    "The Sparse Matrix method and the Jacobi method are two distinct approaches to solving systems of linear equations that arise from discretizing the Laplace equation.\n",
    "\n",
    "1. **Sparse Matrix Method**: This method involves constructing and directly solving a system of linear equations $ AV=b $ using techniques such as matrix inversion or LU decomposition. The time complexity of solving a system of linear equations directly is typically $O(n^3)$ for dense matrices, but by exploiting the sparsity of the matrix **$A$**, this can be reduced to around $O(N^2 log(N))$. Sparse matrix methods are often faster for smaller systems or when high precision is required, but their performance degrades as the size of the system increases due to the cubic dependence on the matrix size in dense cases or log-linear in sparse cases.\n",
    "\n",
    "2. **Jacobi Method**: The Jacobi method is an iterative algorithm with a time complexity of approximately $O(N^2 \\times k)$, where $k$ is the number of iterations required for convergence. Unlike direct methods, the Jacobi method is easier to parallelize and requires less memory, making it more suitable for very large systems where direct methods become impractical. However, the convergence rate of the Jacobi method can be slow, especially for poorly conditioned matrices, and it may require a large number of iterations to reach an acceptable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison Implementation\n",
    "To compare the performance of these two methods, we will measure the time taken to solve the Laplace equation for a range of grid sizes. The code below implements this comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a range of matrix sizes to test\n",
    "matrix_sizes = np.arange(3, 30, 1)\n",
    "times_sparse = []\n",
    "times_jacobi = []\n",
    "\n",
    "# Measure the time taken by each method for each matrix size\n",
    "for N in matrix_sizes:\n",
    "    # Timing the Sparse Matrix Method\n",
    "    start_time_sparse = time.time()\n",
    "    solve_sparse_matrix(N)\n",
    "    end_time_sparse = time.time()\n",
    "    times_sparse.append(end_time_sparse - start_time_sparse)\n",
    "    \n",
    "    # Timing the Jacobi Method\n",
    "    start_time_jacobi = time.time()\n",
    "    jacobi_method(N)\n",
    "    end_time_jacobi = time.time()\n",
    "    times_jacobi.append(end_time_jacobi - start_time_jacobi)\n",
    "\n",
    "# Plotting the performance comparison\n",
    "plt.figure()\n",
    "plt.scatter(matrix_sizes, times_jacobi, label='Jacobi Method', color='b')\n",
    "plt.scatter(matrix_sizes, times_sparse, label='Sparse Matrices', color='g')\n",
    "plt.xlabel('Matrix Order')\n",
    "plt.ylabel('Time (s)')\n",
    "plt.title('Comparison of Numerical Efficiency: Sparse vs. Jacobi')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the results\n",
    "From the plot, we can expect to see that the Sparse Matrix method performs better for smaller matrices due to its efficient handling of the sparse system. However, as the matrix size increases, the Jacobi method might become more competitive, particularly in cases where the matrix is very large and direct methods become computationally expensive.\n",
    "\n",
    "The performance comparison gives us practical insights into when to use each method, balancing between computational efficiency and the size of the problem. This understanding is essential for making informed decisions in numerical simulations, where both the precision and computational cost must be carefully managed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
